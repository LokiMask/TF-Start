{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(10000, 10)\n",
      "(55000, 10)\n"
     ]
    }
   ],
   "source": [
    "#用tf导入数据\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./data/MNIST_data\", one_hot=True)\n",
    "print(mnist.test.labels.shape)\n",
    "print(mnist.train.labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.构建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, filter_shape, strides_x, strides_y, padding, name):\n",
    "    assert padding in ['SAME', 'VALID']\n",
    "    strides = [1, strides_x, strides_y, 1]\n",
    "    with tf.variable_scope(name):\n",
    "        W_conv = tf.get_variable('W', shape=filter_shape)\n",
    "        b_conv = tf.get_variable('b', shape=[filter_shape[-1]])\n",
    "        h_conv = tf.nn.conv2d(x, W_conv, strides=strides, padding=padding)\n",
    "        h_conv_relu = tf.nn.relu(h_conv + b_conv)\n",
    "    return h_conv_relu\n",
    "\n",
    "def max_pooling(x, k_height, k_width, strides_x, strides_y, padding='SAME'):\n",
    "    ksize = [1, k_height, k_width, 1]\n",
    "    strides = [1, strides_x, strides_y, 1]\n",
    "    h_pool = tf.nn.max_pool(x, ksize=ksize, strides=strides, padding=padding)\n",
    "    return h_pool\n",
    "\n",
    "def dropout(x, keep_prob, name = None):\n",
    "    return tf.nn.dropout(x, keep_prob=keep_prob, name=name)\n",
    "\n",
    "def fc(x, in_size, out_size, name, activation=None):\n",
    "    if activation is not None:\n",
    "        assert activation in ['relu', 'sigmoid', 'tanh'], 'Wrong activation function'\n",
    "    with tf.variable_scope(name):\n",
    "        w = tf.get_variable('w', shape= [in_size, out_size], dtype=tf.float32)\n",
    "        b = tf.get_variable('b', [out_size], dtype=tf.float32)\n",
    "        h_fc = tf.nn.xw_plus_b(x, w, b)\n",
    "        if activation == 'relu':\n",
    "            return tf.nn.relu(h_fc)\n",
    "        if activation == 'tanh':\n",
    "            return tf.nn.tanh(h_fc)\n",
    "        if activation == 'sigmoid':\n",
    "            return tf.nn.sigmoid(h_fc)\n",
    "        else:\n",
    "            return h_fc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_input: Tensor(\"inputs/Placeholder:0\", shape=(?, 784), dtype=float32)\n",
      "X:       Tensor(\"Reshape:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "y_input: Tensor(\"inputs/Placeholder_1:0\", shape=(?, 10), dtype=float32)\n",
      "h_conv1: Tensor(\"conv1/Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
      "h_pool1: Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
      "h_conv2: Tensor(\"conv2/Relu:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "h_pool2: Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
      "h_fc1:   Tensor(\"fc1/Relu:0\", shape=(?, 1024), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('inputs'):\n",
    "    X_ = tf.placeholder(tf.float32, [None,  784])\n",
    "    y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "#把x转化为卷积所需要的格式\n",
    "X = tf.reshape(X_, [-1, 28, 28, 1])\n",
    "h_conv1 = conv2d(X, [5, 5, 1, 32], 1, 1, 'SAME', 'conv1')\n",
    "h_pool1 = max_pooling(h_conv1, 2, 2, 2, 2)\n",
    "\n",
    "h_conv2 = conv2d(h_pool1, [5, 5, 32, 64], 1, 1, 'SAME', 'conv2')\n",
    "h_pool2 = max_pooling(h_conv2, 2, 2, 2, 2)\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = fc(h_pool2_flat, 7*7*64, 1024, 'fc1', 'relu')\n",
    "\n",
    "# dropout: 输出的维度和h_fc1一样，只是随机部分值被值为零\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "h_fc2 = fc(h_fc1_drop, 1024, 10, 'fc2')\n",
    "y_conv = tf.nn.softmax(h_fc2)\n",
    "\n",
    "print('X_input:', X_)\n",
    "print('X:      ', X)\n",
    "print('y_input:', y_)\n",
    "print('h_conv1:', h_conv1)\n",
    "print('h_pool1:', h_pool1)\n",
    "print('h_conv2:', h_conv2)\n",
    "print('h_pool2:', h_pool2)\n",
    "print('h_fc1:  ', h_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.训练和预估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.08\n",
      "step 1000, training accuracy 0.96\n",
      "step 2000, training accuracy 0.94\n",
      "step 3000, training accuracy 1\n",
      "step 4000, training accuracy 1\n",
      "step 5000, training accuracy 1\n",
      "step 6000, training accuracy 1\n",
      "step 7000, training accuracy 0.96\n",
      "step 8000, training accuracy 1\n",
      "step 9000, training accuracy 1\n",
      "test accuracy 0.991\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = -tf.reduce_sum(y_ * tf.log(y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(10000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i%1000 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "            X_:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    train_step.run(feed_dict={X_: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "print(\"test accuracy %g\" %accuracy.eval(feed_dict={\n",
    "    X_: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
