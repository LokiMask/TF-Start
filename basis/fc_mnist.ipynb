{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 两层FC做分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用两层全连接做分类，输入[-1,28*28],FC1有1024个neurons,FC2有10个neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division #精确除法 使/是精确的除法\n",
    "from __future__ import absolute_import#绝对引入\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('./data/MNIST_data', one_hot=False, source_url='http://yann.lecun.com/exdb/mnist/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape (55000, 784)\n",
      "training label shape (55000,)\n"
     ]
    }
   ],
   "source": [
    "print('training data shape', mnist.train.images.shape)\n",
    "print('training label shape', mnist.train.labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.构建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#权值初始化\n",
    "def weight_variable(shape):\n",
    "    #用正态分布初始化权值\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    #relu作为激活函数，一般偏置较小\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#input layer\n",
    "X_input = tf.placeholder(tf.float32, [None, 784])\n",
    "y_input = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "#FC1\n",
    "W_fc1 = weight_variable([784, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(X_input, W_fc1) + b_fc1)\n",
    "\n",
    "#FC2\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "logits = tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.训练&评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 500, train cost = 0.224238, acc=0.950000;test cost=0.130887, acc=0.959500\n",
      "step 1000, train cost = 0.146907, acc=0.970000;test cost=0.095745, acc=0.969600\n",
      "step 1500, train cost = 0.045959, acc=0.980000;test cost=0.077362, acc=0.976000\n",
      "step 2000, train cost = 0.040121, acc=0.990000;test cost=0.071335, acc=0.977500\n",
      "step 2500, train cost = 0.038331, acc=0.990000;test cost=0.069818, acc=0.977700\n",
      "step 3000, train cost = 0.011953, acc=1.000000;test cost=0.076723, acc=0.978400\n",
      "step 3500, train cost = 0.018935, acc=1.000000;test cost=0.062385, acc=0.981200\n",
      "step 4000, train cost = 0.027220, acc=0.990000;test cost=0.079847, acc=0.978700\n",
      "step 4500, train cost = 0.002668, acc=1.000000;test cost=0.068271, acc=0.981400\n",
      "step 5000, train cost = 0.001139, acc=1.000000;test cost=0.065974, acc=0.982500\n"
     ]
    }
   ],
   "source": [
    "#1.损失函数：cross_entropy\n",
    "# 如果label 是one-hot的话损失函数要更换 参考https://blog.csdn.net/tz_zs/article/details/76086457\n",
    "cross_entropy = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_input, logits=logits))\n",
    "# 2.优化函数：AdamOptimizer,优化速度要比GradientOptimizer快很多\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)\n",
    "#3.预测结果评估\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), y_input)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "#开始运行\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(5000):\n",
    "    X_batch, y_batch = mnist.train.next_batch(batch_size=100)\n",
    "    cost, acc, _ = sess.run([cross_entropy, accuracy, train_step], feed_dict={X_input:X_batch, y_input:y_batch})\n",
    "    if (i + 1) % 500 == 0:\n",
    "        test_cost, test_acc = sess.run([cross_entropy, accuracy], feed_dict={X_input:mnist.test.images, y_input:mnist.test.labels})\n",
    "        print(\"step {}, train cost = {:.6f}, acc={:.6f};test cost={:.6f}, acc={:.6f}\".format(i+1, cost, acc, test_cost, test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
