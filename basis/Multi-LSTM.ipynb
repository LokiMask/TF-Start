{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(10000, 10)\n",
      "(55000, 10)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # 不打印 warning \n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 用tensorflow 导入数据\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('./data/MNIST_data', one_hot=True) \n",
    "\n",
    "# 看看咱们样本的数量\n",
    "print(mnist.test.labels.shape)\n",
    "print(mnist.train.labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.设置超参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "input_size = 28\n",
    "timestep_size = 28\n",
    "hidden_size = 256\n",
    "layer_num = 2\n",
    "class_num = 10\n",
    "cell_type = 'lstm'\n",
    "\n",
    "x_input = tf.placeholder(tf.float32, [None, 784])\n",
    "y_input = tf.placeholder(tf.float32, [None, class_num])\n",
    "batch_size = tf.placeholder(tf.int32, [])\n",
    "keep_prob = tf.placeholder(tf.float32, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"RNN/RNN/multi_rnn_cell/cell_1_27/dropout/mul:0\", shape=(?, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#转换输入尺寸\n",
    "X = tf.reshape(x_input, [-1, 28, 28])\n",
    "\n",
    "def lstm_cell(cell_type, num_nodes, keep_prob):\n",
    "    assert(cell_type in ['lstm', 'block_lstm'], \"wrong cell type\")\n",
    "    if cell_type == 'lstm':\n",
    "        cell = tf.contrib.rnn.BasicLSTMCell(num_nodes)\n",
    "    else:\n",
    "        cell = tf.contrib.rnn.LSTMBlockCell(num_nodes)\n",
    "    cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
    "    return cell\n",
    "\n",
    "mlstm_cell = tf.contrib.rnn.MultiRNNCell([lstm_cell(cell_type, hidden_size, keep_prob) for _ in range(layer_num)], state_is_tuple=True)\n",
    "#用全0初始化state\n",
    "init_state = mlstm_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "\n",
    "#接下来有几种方法来运行构建好的网络\n",
    "#方法一:调用dynamic_rnn()来让我们构建好的网络运行起来\n",
    "#outputs, state = tf.nn.dynamic_rnn(mlstm_cell, inputs=X, init_state= init_state, time_major=False)\n",
    "#h_state = state[-1][1]\n",
    "\n",
    "#方法二:按时间步展开计算\n",
    "outputs = list()\n",
    "state = init_state\n",
    "with tf.variable_scope('RNN'):\n",
    "    for timestep in range(timestep_size):\n",
    "        (cell_output, state) = mlstm_cell(X[:, timestep, :],state)\n",
    "        outputs.append(cell_output)\n",
    "h_state = outputs[-1]\n",
    "print(h_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.设置loss和优化器，展开训练&测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 500, train cost=0.015462; test cost=0.940000; test cost = 0.012391, acc=0.961300; pass 125.01848340034485s\n",
      "step 1000, train cost=0.004143; test cost=0.990000; test cost = 0.006958, acc=0.979000; pass 249.1424696445465s\n",
      "step 1500, train cost=0.005402; test cost=0.990000; test cost = 0.005350, acc=0.983500; pass 373.2720148563385s\n",
      "step 2000, train cost=0.005764; test cost=0.990000; test cost = 0.004549, acc=0.985400; pass 497.41186356544495s\n",
      "step 2500, train cost=0.001697; test cost=1.000000; test cost = 0.003483, acc=0.988700; pass 621.5442481040955s\n",
      "step 3000, train cost=0.001939; test cost=0.990000; test cost = 0.003256, acc=0.990100; pass 745.5632226467133s\n",
      "step 3500, train cost=0.002817; test cost=0.990000; test cost = 0.002753, acc=0.991100; pass 869.6075649261475s\n",
      "step 4000, train cost=0.008544; test cost=0.980000; test cost = 0.002511, acc=0.991800; pass 993.8090524673462s\n",
      "step 4500, train cost=0.001372; test cost=0.990000; test cost = 0.001889, acc=0.993800; pass 1117.9835555553436s\n",
      "step 5000, train cost=0.003143; test cost=0.980000; test cost = 0.001719, acc=0.994100; pass 1241.9414031505585s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "W =tf.Variable(tf.truncated_normal([hidden_size, class_num], stddev=0.1), dtype=tf.float32)\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[class_num]), dtype=tf.float32)\n",
    "y_pre = tf.nn.softmax(tf.matmul(h_state, W) + bias)\n",
    "\n",
    "#损失\n",
    "cross_entropy = -tf.reduce_mean(y_input * tf.log(y_pre))\n",
    "train_op = tf.train.AdamOptimizer(lr).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_pre, 1), tf.argmax(y_input, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "time0 = time.time()\n",
    "for i in range(5000):\n",
    "    _batch_size = 100\n",
    "    X_batch, y_batch = mnist.train.next_batch(batch_size=_batch_size)\n",
    "    cost, acc, _ = sess.run([cross_entropy, accuracy, train_op], feed_dict={x_input:X_batch, y_input:y_batch, keep_prob:0.5, batch_size:_batch_size})\n",
    "    if (i + 1) % 500 == 0:\n",
    "        test_acc = 0.0\n",
    "        test_cost = 0.0\n",
    "        N = 100\n",
    "        for j in range(N):\n",
    "            X_batch, y_batch = mnist.test.next_batch(batch_size=_batch_size)\n",
    "            _cost, _acc, _ = sess.run([cross_entropy, accuracy, train_op], feed_dict={x_input:X_batch, y_input:y_batch, keep_prob:1.0, batch_size:_batch_size})\n",
    "            test_acc += _acc\n",
    "            test_cost += _cost\n",
    "        print(\"step {}, train cost={:.6f}; test cost={:.6f}; test cost = {:.6f}, acc={:.6f}; pass {}s\".format(i+1, cost, acc, test_cost/N, test_acc/N, time.time() - time0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
